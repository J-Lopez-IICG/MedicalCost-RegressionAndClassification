<h1 align="center">üè• Medical Cost Prediction üè•</h1>

[![Powered by Kedro](https://img.shields.io/badge/powered_by-kedro-ffc900?logo=kedro)](https://kedro.org)

## üéØ Visi√≥n General

Este proyecto Kedro implementa un pipeline de ciencia de datos de extremo a extremo para predecir los costos de seguros m√©dicos y clasificar a los pacientes en categor√≠as de costo. La soluci√≥n utiliza el conjunto de datos "Medical Insurance Cost Dataset", disponible en [Kaggle: Medical Insurance Cost Dataset](https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset), que contiene informaci√≥n demogr√°fica y de salud de individuos. El pipeline ingiere estos datos crudos, los procesa para garantizar su calidad, entrena y eval√∫a modelos de regresi√≥n para predecir costos exactos, y modelos de clasificaci√≥n para predecir si un paciente incurrir√° en costos "Altos" o "Bajos".

El objetivo es demostrar un flujo de trabajo de Machine Learning estructurado y reproducible, donde cada paso, desde la limpieza de datos hasta la generaci√≥n de reportes, est√° encapsulado en un pipeline modular y robusto.

---

## üéØ Hip√≥tesis

La hip√≥tesis central es que las caracter√≠sticas demogr√°ficas y de salud de un individuo no solo permiten predecir sus costos m√©dicos, sino tambi√©n clasificarlo en un grupo de riesgo con alta precisi√≥n. Para validar esto, se plantearon las siguientes sub-hip√≥tesis:

1.  **Hip√≥tesis de Regresi√≥n (Predicci√≥n de Costo):**
    *   **¬øEs posible predecir el costo exacto del seguro (`charges`)?** Se postula que un modelo de regresi√≥n podr√° explicar una porci√≥n significativa de la varianza en los costos (R¬≤ > 0.75).
    *   **¬øCu√°l es el factor m√°s influyente?** Se hipotetiza que ser fumador (`smoker`) ser√°, por un amplio margen, el predictor m√°s determinante del costo, superando a la edad y al IMC.
    *   **¬øExisten efectos de interacci√≥n?** Se espera encontrar una fuerte interacci√≥n entre ser fumador y el IMC, donde el impacto del IMC en los costos se magnifica exponencialmente en individuos fumadores.

2.  **Hip√≥tesis de Clasificaci√≥n (Categorizaci√≥n de Riesgo):**
    *   **¬øSe puede clasificar a los pacientes en categor√≠as de costo 'Alto' o 'Bajo' con alta precisi√≥n?** Se anticipa que los modelos de clasificaci√≥n alcanzar√°n una precisi√≥n superior al 90%.
    *   **¬øQu√© tipo de modelo ser√° m√°s efectivo?** Dada la complejidad y las interacciones no lineales (como la de `smoker` y `bmi`), se hipotetiza que los modelos de ensamblaje (Random Forest, XGBoost) superar√°n en rendimiento a los modelos lineales (Regresi√≥n Log√≠stica) y a otros clasificadores como SVC.

---
## üèóÔ∏è Estructura del Proyecto

El proyecto est√° organizado en una serie de pipelines modulares, cada uno con una responsabilidad espec√≠fica, garantizando un flujo de trabajo claro y reproducible.

```mermaid
graph TD
    A[1. data_engineering] --> B[2. data_processing];
    B --> C[3. exploratory_data];
    B --> D[4. feature_engineering];
    D --> E[5. model_regression];
    D --> F[6. model_classification];
```

```text
src/medicalcost/pipelines/
‚îú‚îÄ‚îÄ data_engineering/     # 1. üì• Descarga y carga de datos crudos desde Kaggle.
‚îú‚îÄ‚îÄ data_processing/      # 2. üßº Limpieza y validaci√≥n de datos (nulos, duplicados).
‚îú‚îÄ‚îÄ exploratory_data/     # 3. üó∫Ô∏è Generaci√≥n de gr√°ficos para el An√°lisis Exploratorio de Datos (EDA).
‚îú‚îÄ‚îÄ feature_engineering/  # 4. üõ†Ô∏è Creaci√≥n de caracter√≠sticas para modelado (One-Hot Encoding, etc.).
‚îú‚îÄ‚îÄ model_regression/     # 5. üìà Entrenamiento y evaluaci√≥n de modelos de Regresi√≥n (Lineal, RF, XGBoost).
‚îî‚îÄ‚îÄ model_classification/ # 6. üìä Entrenamiento y evaluaci√≥n de modelos de Clasificaci√≥n (Log-Reg, SVC, RF, XGBoost).
```
</div>

---

## ‚öôÔ∏è Flujo de Preparaci√≥n de Datos

El preprocesamiento de datos es un pilar fundamental de este proyecto, automatizado a trav√©s de una secuencia de pipelines de Kedro para garantizar la consistencia y reproducibilidad. El flujo es el siguiente:

1.  **Ingesta de Datos (`data_engineering`)**:
    *   El pipeline se conecta a la API de Kaggle para descargar y cargar el dataset crudo, asegurando que siempre se trabaje con la fuente de datos original.

2.  **Limpieza y Validaci√≥n (`data_processing`)**:
    *   **Manejo de Nulos y Duplicados**: Se eliminan sistem√°ticamente todas las filas que contienen valores nulos o que son duplicados exactos, garantizando la integridad del dataset.
    *   **Conversi√≥n de Tipos**: Las columnas `sex`, `smoker` y `region` se convierten al tipo de dato `category` para optimizar el uso de memoria y prepararlas para la codificaci√≥n.

3.  **Ingenier√≠a de Caracter√≠sticas (`feature_engineering`)**:
    *   **Creaci√≥n de Variable Objetivo (Clasificaci√≥n)**: Se crea la columna `cost_category` para los modelos de clasificaci√≥n. Un paciente se etiqueta como `1` (Alto costo) si sus `charges` superan la mediana del dataset, y `0` (Bajo costo) en caso contrario.
    *   **Codificaci√≥n One-Hot**: Las variables categ√≥ricas (`sex`, `smoker`, `region`) se transforman en formato num√©rico usando One-Hot Encoding con `drop_first=True` para evitar multicolinealidad.
    *   **Manejo de Outliers**: Se toma la decisi√≥n expl√≠cita de **no eliminar outliers**. Los valores extremos, especialmente en `charges` para fumadores con alto IMC, son considerados informaci√≥n predictiva crucial y no ruido.

---

## üí° Resultados: Una Historia en Tres Actos

El pipeline gener√≥ una serie de reportes y visualizaciones que, en conjunto, nos permiten contar la historia de los datos y validar nuestras hip√≥tesis. Cada artefacto es una pieza del rompecabezas.

### Acto 1: Exploraci√≥n de los Datos

El an√°lisis exploratorio (EDA) fue fundamental para entender la naturaleza de los datos y formular nuestras hip√≥tesis. Cada gr√°fico nos cont√≥ una parte de la historia.

1.  **Perfil de la Poblaci√≥n**: Primero, analizamos las distribuciones demogr√°ficas. La edad presenta una distribuci√≥n bastante uniforme, el IMC (`bmi`) sigue una curva normal, y la mayor√≠a de los asegurados tienen pocos o ning√∫n hijo.

    <img src="data/08_reporting/exploratory/plot_age_histogram.png" alt="Distribuci√≥n de Edad" width="600"/>
    <img src="data/08_reporting/exploratory/plot_bmi_histogram.png" alt="Distribuci√≥n de IMC" width="600"/>
    <img src="data/08_reporting/exploratory/plot_children_barplot.png" alt="Distribuci√≥n de Hijos" width="600"/>

2.  **El Comportamiento de los Costos (`charges`)**: La variable objetivo muestra un fuerte sesgo positivo. La gran mayor√≠a de los costos son bajos, pero existe una "larga cola" de costos muy elevados, lo que sugiere que ciertos factores pueden disparar los gastos de manera exponencial.

    <img src="data/08_reporting/exploratory/plot_charges_histogram.png" alt="Distribuci√≥n de Costos" width="700"/>

3.  **B√∫squeda de Pistas: Correlaciones e Interacciones**:
    *   **Correlaciones Num√©ricas**: El mapa de calor inicial mostr√≥ correlaciones positivas pero d√©biles de la edad y el IMC con los costos. Ninguna variable num√©rica por s√≠ sola parec√≠a ser un predictor dominante.
    *   **El Factor Decisivo**: El gr√°fico de caja revel√≥ la abismal diferencia en costos entre fumadores y no fumadores. Los fumadores no solo pagan m√°s, sino que la variabilidad de sus costos es inmensa.
    *   **La Interacci√≥n Clave**: El gr√°fico de dispersi√≥n confirm√≥ nuestra hip√≥tesis de interacci√≥n. Mientras que un IMC alto aumenta los costos para todos, este efecto se magnifica exponencialmente en individuos fumadores.

    <img src="data/08_reporting/exploratory/correlation_heatmap.png" alt="Correlaci√≥n Num√©rica" width="600"/>
    <img src="data/08_reporting/exploratory/smoker_vs_charges.png" alt="Fumador vs Costo" width="600"/>
    <img src="data/08_reporting/exploratory/bmi_smoker_interaction.png" alt="Interacci√≥n IMC-Fumador" width="600"/>

4.  **Relaciones Lineales D√©biles**: Los gr√°ficos de regresi√≥n univariada confirmaron que, de forma aislada, variables como la edad, el IMC y el n√∫mero de hijos tienen una correlaci√≥n positiva pero d√©bil con los costos (R¬≤ bajos). Esto reforz√≥ la idea de que las interacciones son m√°s importantes que los efectos individuales.

    <img src="data/08_reporting/exploratory/age_vs_charges_regression.png" alt="Regresi√≥n Edad" width="600"/>
    <img src="data/08_reporting/exploratory/bmi_vs_charges_regression.png" alt="Regresi√≥n IMC" width="600"/>
    <img src="data/08_reporting/exploratory/children_vs_charges_regression.png" alt="Regresi√≥n Hijos" width="600"/>

5.  **An√°lisis de Outliers**: Los diagramas de caja revelaron la presencia de valores at√≠picos, especialmente en el IMC y los costos. Se decidi√≥ conservarlos, ya que representan escenarios reales y de alto impacto (ej. fumadores con obesidad) que son cruciales para que los modelos aprendan a predecir los casos m√°s extremos.

    <img src="data/08_reporting/exploratory/plot_age_boxplot.png" alt="Boxplot Edad" width="600"/>
    <img src="data/08_reporting/exploratory/plot_bmi_boxplot.png" alt="Boxplot IMC" width="600"/>
    <img src="data/08_reporting/exploratory/plot_charges_boxplot.png" alt="Boxplot Charges" width="600"/>

### Acto 2: Predicci√≥n del Costo Exacto (Regresi√≥n)

El objetivo aqu√≠ era responder: **¬øPodemos predecir el costo exacto del seguro?**

1.  **Correlaci√≥n de Caracter√≠sticas Finales**: Antes de entrenar, se gener√≥ un mapa de calor con todas las variables (incluyendo las dummies). Este mapa confirm√≥ que `smoker_yes` es, con diferencia, la caracter√≠stica con la correlaci√≥n m√°s alta (0.79) con `charges`.

    <img src="data/08_reporting/regression/feature_correlation_heatmap.png" alt="Correlaci√≥n Final" width="700"/>

2.  **Comparaci√≥n de Modelos**: Se compararon tres modelos, y los resultados, visibles en el gr√°fico `r2_comparison_plot.png`, confirmaron que los modelos de ensamblaje (Random Forest y XGBoost) superaron con creces al modelo lineal simple.

<img src="data/08_reporting/regression/r2_comparison_plot.png" alt="R2 Comparison" width="700"/>

3.  **El Campe√≥n y su Veredicto**: El modelo **XGBoost Regressor** se coron√≥ como el campe√≥n, explicando un **90.12%** de la varianza en los costos (R¬≤). La importancia de sus caracter√≠sticas, extra√≠da del reporte `evaluation_output_xgb.txt`, confirm√≥ la hip√≥tesis inicial de forma rotunda:

| Caracter√≠stica    | Importancia |
| :---------------- | :---------- |
| **smoker_yes**    | **0.7996**  |
| bmi               | 0.1026      |
| age               | 0.0457      |
| ... (otras)       | < 0.015     |

> ‚úÖ **Conclusi√≥n de Regresi√≥n**: Es posible predecir los costos con alta precisi√≥n (R¬≤ > 0.90), y ser fumador (`smoker_yes`) es, por un margen abrumador, el factor m√°s determinante.
> ‚úÖ **Conclusi√≥n de Regresi√≥n**: Es posible predecir los costos con alta precisi√≥n (R¬≤ ‚âà 0.90), y ser fumador (`smoker_yes`) es, por un margen abrumador, el factor m√°s determinante.

### Acto 3: Clasificaci√≥n del Riesgo de Costo (Clasificaci√≥n)

Finalmente, se busc√≥ responder: **¬øPodemos clasificar a los pacientes en categor√≠as de 'Alto' o 'Bajo' costo?**

1.  **Optimizaci√≥n de Modelos**: Para asegurar el m√°ximo rendimiento, se realiz√≥ una b√∫squeda de hiperpar√°metros (GridSearch) para los modelos m√°s complejos. Los mapas de calor generados nos permitieron visualizar c√≥mo diferentes combinaciones de par√°metros afectaban la precisi√≥n, eligiendo as√≠ la mejor configuraci√≥n para cada modelo.

    <img src="data/08_reporting/classification/grid_search_heatmap_xgb.png" alt="GridSearch XGBoost" width="600"/>

2.  **Rendimiento Final**: El resumen de rendimiento, generado en el dataset `classification_summary_output`, muestra una clara victoria de los modelos de ensamblaje, superando la meta del 90% de precisi√≥n.

| Modelo                          | Accuracy (Precisi√≥n Final) |
| :------------------------------ | :------------------------: |
| **XGBoost**                     |         **94.78%**         |
| Random Forest                   |           94.78%           |
| Support Vector Classifier (SVC) |           92.91%           |
| Regresi√≥n Log√≠stica             |           90.67%           |

> El modelo **RXGBoost** se corona como el campe√≥n, logrando la mayor precisi√≥n en la clasificaci√≥n de riesgo de costo. üèÜ

3.  **Capacidad de Discriminaci√≥n (Curvas ROC)**: La comparaci√≥n de las curvas ROC confirma visualmente el rendimiento superior. Los modelos de ensamblaje y SVC se agrupan en la esquina superior izquierda, con √°reas bajo la curva (AUC) de 0.95 o m√°s, lo que indica una capacidad de discriminaci√≥n casi perfecta.

<img src="data/08_reporting/classification/roc_curves_comparison.png" alt="ROC Curves" width="700"/>

4.  **Interpretabilidad del Modelo Lineal**: Aunque la Regresi√≥n Log√≠stica no fue el modelo m√°s preciso, su interpretabilidad es valiosa. El gr√°fico de importancia de caracter√≠sticas muestra que ser fumador (`smoker_yes`) tiene el impacto positivo m√°s fuerte para ser clasificado como de 'Alto Costo', seguido por el IMC y la edad. Esto alinea los hallazgos de clasificaci√≥n con los de regresi√≥n.

    <img src="data/08_reporting/classification/feature_importance_log_reg.png" alt="Importancia Regresi√≥n Log√≠stica" width="700"/>

> ‚úÖ **Conclusi√≥n de Clasificaci√≥n**: Es posible clasificar a los pacientes por riesgo de costo con una precisi√≥n extremadamente alta (‚âà95%), y los modelos de ensamblaje son la mejor herramienta para esta tarea.

---

## üõ†Ô∏è Configuraci√≥n de Kaggle

Para poder ejecutar este pipeline, es necesario configurar las credenciales de la API de Kaggle.

1.  **Crea un token de API en Kaggle:**
    *   Ve a tu perfil de Kaggle y entra en la secci√≥n "Settings": [https://www.kaggle.com/settings](https://www.kaggle.com/settings)
    *   En la secci√≥n "API", haz clic en **"Create New Token"**. Se descargar√° un archivo llamado `kaggle.json`.

2.  **Coloca el archivo de credenciales:**
    *   Mueve el archivo `kaggle.json` a la carpeta `.kaggle` dentro de tu directorio de usuario.
        *   En Windows: `C:\Users\<Tu-Usuario>\.kaggle\kaggle.json`
        *   En Linux/macOS: `~/.kaggle/kaggle.json`

Una vez completados estos pasos, el pipeline podr√° autenticarse con Kaggle para descargar los datos necesarios.

---

## üöÄ Instalaci√≥n y Ejecuci√≥n

Sigue estos pasos para configurar y ejecutar el proyecto en tu m√°quina local. Se requiere Python 3.11.9.

### 1. Clonar el Repositorio

Primero, clona este repositorio.

```bash
git clone https://github.com/J-Lopez-IICG/MedicalCostKedro.git
cd MedicalCostKedro-WorkInProgress
```

### 2. Crear y Activar un Entorno Virtual

Es una pr√°ctica recomendada utilizar un entorno virtual para aislar las dependencias del proyecto.

```bash
# Crear el entorno virtual
python -m venv venv

# Activar en Windows (PowerShell)
.\venv\Scripts\Activate.ps1

# Activar en macOS/Linux
# source venv/bin/activate
```

### 3. Instalar Dependencias

Una vez que el entorno virtual est√© activado, instala todas las librer√≠as necesarias.

```bash
pip install -r requirements.txt
```

### 4. Ejecutar el Pipeline

Con las dependencias instaladas, puedes ejecutar el pipeline completo con un solo comando.

```sh
kedro run
```

Esto ejecutar√° todos los nodos en secuencia, generando los datos limpios, los modelos entrenados y las gr√°ficas de resultados en la carpeta `data/`.

---

## üìì Desarrollo con Notebooks

La carpeta `notebooks` contiene los Jupyter Notebooks utilizados durante la fase de exploraci√≥n y desarrollo.

Para trabajar con ellos de forma interactiva dentro del contexto de Kedro, ejecuta:

```bash
kedro jupyter lab
# o tambi√©n
kedro jupyter notebook
```

> **Nota**: Al usar estos comandos, Kedro inicia el notebook con las variables `context`, `session`, `catalog` y `pipelines` ya cargadas, facilitando la interacci√≥n con los datos y funciones del proyecto.
