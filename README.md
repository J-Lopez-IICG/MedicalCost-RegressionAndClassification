<h1 align="center">üè• Medical Cost Prediction üè•</h1>

[![Powered by Kedro](https://img.shields.io/badge/powered_by-kedro-ffc900?logo=kedro)](https://kedro.org)

## üéØ Visi√≥n General

Este proyecto Kedro implementa un pipeline de ciencia de datos de extremo a extremo para predecir los costos de seguros m√©dicos y clasificar a los pacientes en categor√≠as de costo. La soluci√≥n utiliza el conjunto de datos "Medical Insurance Cost Dataset", disponible en [Kaggle: Medical Insurance Cost Dataset](https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset), que contiene informaci√≥n demogr√°fica y de salud de individuos. El pipeline ingiere estos datos crudos, los procesa para garantizar su calidad, entrena y eval√∫a modelos de regresi√≥n para predecir costos exactos, y modelos de clasificaci√≥n para predecir si un paciente incurrir√° en costos "Altos" o "Bajos".

El objetivo es demostrar un flujo de trabajo de Machine Learning estructurado y reproducible, donde cada paso, desde la limpieza de datos hasta la generaci√≥n de reportes, est√° encapsulado en un pipeline modular y robusto.

---

## üéØ Hip√≥tesis

La hip√≥tesis central es que las caracter√≠sticas demogr√°ficas y de salud de un individuo no solo permiten predecir sus costos m√©dicos, sino tambi√©n clasificarlo en un grupo de riesgo con alta precisi√≥n. Para validar esto, se plantearon las siguientes sub-hip√≥tesis:

1.  **Hip√≥tesis de Regresi√≥n (Predicci√≥n de Costo):**
    *   **¬øEs posible predecir el costo exacto del seguro (`charges`)?** Se postula que un modelo de regresi√≥n podr√° explicar una porci√≥n significativa de la varianza en los costos (R¬≤ > 0.75).
    *   **¬øCu√°l es el factor m√°s influyente?** Se hipotetiza que ser fumador (`smoker`) ser√°, por un amplio margen, el predictor m√°s determinante del costo, superando a la edad y al IMC.
    *   **¬øExisten efectos de interacci√≥n?** Se espera encontrar una fuerte interacci√≥n entre ser fumador y el IMC, donde el impacto del IMC en los costos se magnifica exponencialmente en individuos fumadores.

2.  **Hip√≥tesis de Clasificaci√≥n (Categorizaci√≥n de Riesgo):**
    *   **¬øSe puede clasificar a los pacientes en categor√≠as de costo 'Alto' o 'Bajo' con alta precisi√≥n?** Se anticipa que los modelos de clasificaci√≥n alcanzar√°n una precisi√≥n superior al 90%.
    *   **¬øQu√© tipo de modelo ser√° m√°s efectivo?** Dada la complejidad y las interacciones no lineales (como la de `smoker` y `bmi`), se hipotetiza que los modelos de ensamblaje (Random Forest, XGBoost) superar√°n en rendimiento a los modelos lineales (Regresi√≥n Log√≠stica) y a otros clasificadores como SVC.

---
## üèóÔ∏è Estructura del Proyecto

El proyecto est√° organizado en una serie de pipelines modulares, cada uno con una responsabilidad espec√≠fica, garantizando un flujo de trabajo claro y reproducible.

```mermaid
graph TD
    A[1. data_engineering] --> B[2. data_processing];
    B --> C[3. exploratory_data];
    B --> D[4. feature_engineering];
    D --> E[5. model_regression];
    D --> F[6. model_classification];
```

```text
src/medicalcost/pipelines/
‚îú‚îÄ‚îÄ data_engineering/     # 1. üì• Descarga y carga de datos crudos desde Kaggle.
‚îú‚îÄ‚îÄ data_processing/      # 2. üßº Limpieza y validaci√≥n de datos (nulos, duplicados).
‚îú‚îÄ‚îÄ exploratory_data/     # 3. üó∫Ô∏è Generaci√≥n de gr√°ficos para el An√°lisis Exploratorio de Datos (EDA).
‚îú‚îÄ‚îÄ feature_engineering/  # 4. üõ†Ô∏è Creaci√≥n de caracter√≠sticas para modelado (One-Hot Encoding, etc.).
‚îú‚îÄ‚îÄ model_regression/     # 5. üìà Entrenamiento y evaluaci√≥n de modelos de Regresi√≥n (Lineal, RF, XGBoost).
‚îî‚îÄ‚îÄ model_classification/ # 6. üìä Entrenamiento y evaluaci√≥n de modelos de Clasificaci√≥n (Log-Reg, SVC, RF, XGBoost).
```
</div>

---

## ‚öôÔ∏è Flujo de Preparaci√≥n de Datos

El preprocesamiento de datos es un pilar fundamental de este proyecto, automatizado a trav√©s de una secuencia de pipelines de Kedro para garantizar la consistencia y reproducibilidad. El flujo es el siguiente:

1.  **Ingesta de Datos (`data_engineering`)**:
    *   El pipeline se conecta a la API de Kaggle para descargar y cargar el dataset crudo, asegurando que siempre se trabaje con la fuente de datos original.

2.  **Limpieza y Validaci√≥n (`data_processing`)**:
    *   **Manejo de Nulos y Duplicados**: Se eliminan sistem√°ticamente todas las filas que contienen valores nulos o que son duplicados exactos, garantizando la integridad del dataset.
    *   **Conversi√≥n de Tipos**: Las columnas `sex`, `smoker` y `region` se convierten al tipo de dato `category` para optimizar el uso de memoria y prepararlas para la codificaci√≥n.

3.  **Ingenier√≠a de Caracter√≠sticas (`feature_engineering`)**:
    *   **Creaci√≥n de Variable Objetivo (Clasificaci√≥n)**: Se crea la columna `cost_category` para los modelos de clasificaci√≥n. Un paciente se etiqueta como `1` (Alto costo) si sus `charges` superan la mediana del dataset, y `0` (Bajo costo) en caso contrario.
    *   **Codificaci√≥n One-Hot**: Las variables categ√≥ricas (`sex`, `smoker`, `region`) se transforman en formato num√©rico usando One-Hot Encoding con `drop_first=True` para evitar multicolinealidad.
    *   **Manejo de Outliers**: Se toma la decisi√≥n expl√≠cita de **no eliminar outliers**. Los valores extremos, especialmente en `charges` para fumadores con alto IMC, son considerados informaci√≥n predictiva crucial y no ruido.

---

## üí° Resultados: Una Historia en Tres Actos

El pipeline gener√≥ una serie de reportes y visualizaciones que, en conjunto, cuentan la historia de los datos y el rendimiento de los modelos.

### Acto 1: Exploraci√≥n de los Datos

El an√°lisis exploratorio inicial (EDA) revel√≥ patrones clave que sentaron las bases para las hip√≥tesis del proyecto.

1.  **Ser Fumador es el Factor Decisivo**: El primer hallazgo contundente fue la abismal diferencia en costos entre fumadores y no fumadores. Los fumadores no solo pagan m√°s, sino que la variabilidad de sus costos es inmensa.

    <img src="data/08_reporting/exploratory/smoker_vs_charges.png" alt="Smoker vs Charges" width="600"/>

2.  **La Interacci√≥n Exponencial entre IMC y Fumar**: El an√°lisis de interacciones demostr√≥ que, si bien un IMC alto aumenta los costos para todos, este efecto se magnifica exponencialmente en individuos fumadores. Esto sugiere que los modelos no lineales ser√≠an m√°s efectivos.

    <img src="data/08_reporting/exploratory/bmi_smoker_interaction.png" alt="BMI Smoker Interaction" width="700"/>

### Acto 2: Predicci√≥n del Costo Exacto (Regresi√≥n)

El objetivo aqu√≠ era responder: **¬øPodemos predecir el costo exacto del seguro?** Se compararon tres modelos, y los resultados confirmaron que los modelos de ensamblaje superaron con creces al modelo lineal.

<img src="data/08_reporting/regression/r2_comparison_plot.png" alt="R2 Comparison" width="700"/>

El modelo **XGBoost Regressor** se coron√≥ como el campe√≥n, explicando un **90.25%** de la varianza en los costos del seguro en el conjunto de prueba.

La importancia de las caracter√≠sticas del modelo ganador confirm√≥ la hip√≥tesis inicial de forma rotunda:

| Caracter√≠stica    | Importancia |
| :---------------- | :---------- |
| **smoker_yes**    | **0.8307**  |
| bmi               | 0.0991      |
| age               | 0.0440      |
| children          | 0.0108      |
| sex_male          | 0.0047      |
| region_southwest  | 0.0047      |
| region_northwest  | 0.0036      |
| region_southeast  | 0.0023      |

> ‚úÖ **Conclusi√≥n de Regresi√≥n**: Es posible predecir los costos con alta precisi√≥n (R¬≤ > 0.90), y ser fumador (`smoker_yes`) es, por un margen abrumador, el factor m√°s determinante.

### Acto 3: Clasificaci√≥n del Riesgo de Costo (Clasificaci√≥n)

Finalmente, se busc√≥ responder: **¬øPodemos clasificar a los pacientes en categor√≠as de 'Alto' o 'Bajo' costo?** Los resultados fueron excelentes, superando el 90% de precisi√≥n anticipado.

A continuaci√≥n se muestra el resumen de rendimiento de los modelos:

| Modelo                          | Accuracy (Precisi√≥n Final) |
| :------------------------------ | :------------------------: |
| **XGBoost**                     |         **94.78%**         |
| Random Forest                   |           94.78%           |
| Support Vector Classifier (SVC) |           92.91%           |
| Regresi√≥n Log√≠stica             |           90.67%           |

Los modelos **XGBoost** y **Random Forest** demostraron un rendimiento pr√°cticamente id√©ntico y superior, validando la hip√≥tesis de que los modelos de ensamblaje ser√≠an los m√°s efectivos.

La comparaci√≥n de las curvas ROC confirma visualmente el rendimiento superior de los modelos de ensamblaje, con √°reas bajo la curva (AUC) de 0.99 para RF y 0.95 para XGBoost, indicando una capacidad de discriminaci√≥n casi perfecta.

<img src="data/08_reporting/classification/roc_curves_comparison.png" alt="ROC Curves" width="700"/>

> ‚úÖ **Conclusi√≥n de Clasificaci√≥n**: Es posible clasificar a los pacientes por riesgo de costo con una precisi√≥n extremadamente alta (‚âà95%), y los modelos de ensamblaje son la mejor herramienta para esta tarea.

---

## ÔøΩ Configuraci√≥n de Kaggle

Para poder ejecutar este pipeline, es necesario configurar las credenciales de la API de Kaggle.

1.  **Crea un token de API en Kaggle:**
    *   Ve a tu perfil de Kaggle y entra en la secci√≥n "Settings": [https://www.kaggle.com/settings](https://www.kaggle.com/settings)
    *   En la secci√≥n "API", haz clic en **"Create New Token"**. Se descargar√° un archivo llamado `kaggle.json`.

2.  **Coloca el archivo de credenciales:**
    *   Mueve el archivo `kaggle.json` a la carpeta `.kaggle` dentro de tu directorio de usuario.
        *   En Windows: `C:\Users\<Tu-Usuario>\.kaggle\kaggle.json`
        *   En Linux/macOS: `~/.kaggle/kaggle.json`

Una vez completados estos pasos, el pipeline podr√° autenticarse con Kaggle para descargar los datos necesarios.

---

## üöÄ Instalaci√≥n y Ejecuci√≥n

Sigue estos pasos para configurar y ejecutar el proyecto en tu m√°quina local. Se requiere Python 3.11.9.

### 1. Clonar el Repositorio

Primero, clona este repositorio.

```bash
git clone https://github.com/J-Lopez-IICG/MedicalCostKedro.git
cd MedicalCostKedro-WorkInProgress
```

### 2. Crear y Activar un Entorno Virtual

Es una pr√°ctica recomendada utilizar un entorno virtual para aislar las dependencias del proyecto.

```bash
# Crear el entorno virtual
python -m venv venv

# Activar en Windows (PowerShell)
.\venv\Scripts\Activate.ps1

# Activar en macOS/Linux
# source venv/bin/activate
```

### 3. Instalar Dependencias

Una vez que el entorno virtual est√© activado, instala todas las librer√≠as necesarias.

```bash
pip install -r requirements.txt
```

### 4. Ejecutar el Pipeline

Con las dependencias instaladas, puedes ejecutar el pipeline completo con un solo comando.

```sh
kedro run
```

Esto ejecutar√° todos los nodos en secuencia, generando los datos limpios, los modelos entrenados y las gr√°ficas de resultados en la carpeta `data/`.

---

## üìì Desarrollo con Notebooks

La carpeta `notebooks` contiene los Jupyter Notebooks utilizados durante la fase de exploraci√≥n y desarrollo.

Para trabajar con ellos de forma interactiva dentro del contexto de Kedro, ejecuta:

```bash
kedro jupyter lab
# o tambi√©n
kedro jupyter notebook
```

> **Nota**: Al usar estos comandos, Kedro inicia el notebook con las variables `context`, `session`, `catalog` y `pipelines` ya cargadas, facilitando la interacci√≥n con los datos y funciones del proyecto.
