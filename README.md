<h1 align="center">ğŸ¥ Medical Cost Prediction ğŸ¥</h1>

[![Powered by Kedro](https://img.shields.io/badge/powered_by-kedro-ffc900?logo=kedro)](https://kedro.org)

## ğŸ¯ VisiÃ³n General

Este proyecto Kedro implementa un pipeline de ciencia de datos de extremo a extremo para predecir los costos de seguros mÃ©dicos y clasificar a los pacientes en categorÃ­as de costo. La soluciÃ³n utiliza el conjunto de datos "Medical Insurance Cost Dataset", disponible en [Kaggle: Medical Insurance Cost Dataset](https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset), que contiene informaciÃ³n demogrÃ¡fica y de salud de individuos. El pipeline ingiere estos datos crudos, los procesa para garantizar su calidad, entrena y evalÃºa modelos de regresiÃ³n para predecir costos exactos, y modelos de clasificaciÃ³n para predecir si un paciente incurrirÃ¡ en costos "Altos" o "Bajos".

El objetivo es demostrar un flujo de trabajo de Machine Learning estructurado y reproducible, donde cada paso, desde la limpieza de datos hasta la generaciÃ³n de reportes, estÃ¡ encapsulado en un pipeline modular y robusto.

---

## HipÃ³tesis

La hipÃ³tesis central de este anÃ¡lisis es que **factores demogrÃ¡ficos y de salud pueden ser utilizados para predecir los costos de seguros mÃ©dicos y clasificar a los pacientes por riesgo de costo**. Se espera que, mediante algoritmos de regresiÃ³n y clasificaciÃ³n, se puedan construir modelos capaces de estimar los costos y distinguir con alta precisiÃ³n entre pacientes de "alto" y "bajo" costo, basÃ¡ndose en caracterÃ­sticas como la edad, el IMC, el hÃ¡bito de fumar, etc.

---
## Estructura del Proyecto
<div>

```
src/medicalcost/pipelines/
â”œâ”€â”€ data_engineering/     # 1. ğŸ“¥ Descarga y carga de datos crudos desde Kaggle.
â”‚
â”œâ”€â”€ data_processing/      # 2. ğŸ§¼ Limpieza, validaciÃ³n y conversiÃ³n de tipos de datos.
â”‚
â”œâ”€â”€ model_regression/     # 3. ğŸ“ˆ Entrenamiento y evaluaciÃ³n del modelo de RegresiÃ³n Lineal.
â”‚   â”‚                     #    - Predice el costo exacto del seguro.
â”‚   â”‚                     #    - Genera reportes y grÃ¡ficos de regresiÃ³n.
â”‚   â””â”€ nodes.py
â”‚
â””â”€â”€ model_classification/ # 4. ğŸ“Š Entrenamiento y evaluaciÃ³n de modelos de ClasificaciÃ³n.
    â”‚                     #    - Predice si el costo serÃ¡ 'Alto' o 'Bajo'.
    â”‚                     #    - Compara RegresiÃ³n LogÃ­stica, SVC, XGBoost y Random Forest.
    â”‚                     #    - Optimiza hiperparÃ¡metros con GridSearchCV.
    â””â”€ nodes.py
```
</div>

---

## âš™ï¸ PreparaciÃ³n de Datos

*   **Manejo de Datos Nulos**: El pipeline identifica y elimina sistemÃ¡ticamente registros con valores faltantes para asegurar la calidad del dataset.
*   **CodificaciÃ³n de Variables CategÃ³ricas**: Se transformaron variables como `sex`, `smoker` y `region` en formatos numÃ©ricos (One-Hot Encoding) para que los modelos pudieran procesarlas.
*   **CreaciÃ³n de Variable Objetivo para ClasificaciÃ³n**: Se transformÃ³ la variable `charges` en una variable binaria `cost_category` ('Alto'/'Bajo') para el problema de clasificaciÃ³n, utilizando la mediana como umbral.
*   **AutomatizaciÃ³n del Flujo de Datos**: Al encapsular todo el proceso en pipelines de Kedro, se garantiza que los datos para el modelado sean completamente automatizados y reproducibles.

---

## ğŸ’¡ Resultados del Modelo

Esta secciÃ³n presenta las conclusiones detalladas y los artefactos generados por los pipelines de Kedro, que encapsulan el proceso de modelado predictivo para la regresiÃ³n de costos y la clasificaciÃ³n de categorÃ­as de costo. Hemos realizado un anÃ¡lisis comparativo exhaustivo de mÃºltiples modelos, incluyendo un riguroso ajuste de hiperparÃ¡metros para los modelos de clasificaciÃ³n mediante **validaciÃ³n cruzada K-Fold (Stratified K-Fold)**.

### Modelos de RegresiÃ³n

El modelo de RegresiÃ³n Lineal MÃºltiple entrenado en el pipeline `model_regression` obtuvo un **R-cuadrado de 0.7836**.

**Impacto de cada variable en el costo:**
*   **`smoker_yes`**: Es, por un margen enorme, el factor mÃ¡s determinante. Aumenta el costo en **+$23,600**.
*   **`age`** y **`bmi`**: Son los siguientes factores mÃ¡s importantes, aumentando el costo en **+$257** y **+$337** por cada unidad, respectivamente.
*   **`children`**: TambiÃ©n tiene un impacto positivo notable (+$474 por hijo).
*   **`sex_male`** y la **`region`**: Tienen un impacto mucho menor y, en algunos casos, negativo.

### Modelos de ClasificaciÃ³n: Random Forest es el Modelo con Mejor Rendimiento

Tras el ajuste de hiperparÃ¡metros, el modelo **Random Forest** demostrÃ³ ser el mÃ¡s efectivo para la clasificaciÃ³n de costos:

| Modelo | Accuracy (PrecisiÃ³n Final) |
| :--- | :---: |
| RegresiÃ³n LogÃ­stica | 89.93% |
| Support Vector Classifier (SVC) | 92.54% |
| XGBoost | 92.91% |
| **Random Forest** | **94.03%** |

> ğŸ† El modelo **Random Forest optimizado** es el campeÃ³n indiscutible de este anÃ¡lisis, logrando la mayor precisiÃ³n.
---
### ğŸ“Š VisualizaciÃ³n de Resultados

Los pipelines generan diversas visualizaciones para entender el comportamiento de los datos y el rendimiento de los modelos.

**GrÃ¡ficos de RegresiÃ³n Univariada y CorrelaciÃ³n:**
*   **RegresiÃ³n Lineal: Costos del Seguro vs. Edad**: Muestra una tendencia positiva, con datos agrupados en "bandas" (explicadas por el hÃ¡bito de fumar).
    ![RegresiÃ³n Lineal: Costos del Seguro vs. Edad](data/08_reporting/age_vs_charges.png)
    > A mayor edad, mayor es el costo del seguro. Sin embargo, el bajo RÂ² (0.09) y las "bandas" visuales sugieren que la edad por sÃ­ sola no es un buen predictor y que otro factor (el hÃ¡bito de fumar) estÃ¡ influyendo fuertemente.
*   **RegresiÃ³n Lineal: Costos del Seguro vs. IMC (BMI)**: RelaciÃ³n positiva mÃ¡s dÃ©bil y dispersa.
    ![RegresiÃ³n Lineal: Costos del Seguro vs. IMC (BMI)](data/08_reporting/bmi_vs_charges.png)
    > Existe una leve tendencia a que un mayor IMC se relacione con mayores costos, pero la relaciÃ³n es muy dÃ©bil (RÂ² de 0.04) y los datos estÃ¡n muy dispersos, indicando que el IMC por sÃ­ solo tiene un poder predictivo limitado.
*   **DistribuciÃ³n de Costos para Fumadores vs. No Fumadores**: Revela una diferencia masiva en costos, siendo el hÃ¡bito de fumar un factor clave.
    ![DistribuciÃ³n de Costos para Fumadores vs. No Fumadores](data/08_reporting/smoker_vs_charges.png)
    > Este es el hallazgo mÃ¡s contundente. Ser fumador dispara los costos del seguro de manera drÃ¡stica. La mediana de costos para fumadores es significativamente mÃ¡s alta que incluso los costos mÃ¡s extremos de los no fumadores.
*   **InteracciÃ³n entre IMC, ser Fumador y Costos del Seguro**: Muestra cÃ³mo el IMC impacta drÃ¡sticamente los costos para fumadores, un claro efecto de interacciÃ³n.
    ![InteracciÃ³n entre IMC, ser Fumador y Costos del Seguro](data/08_reporting/bmi_smoker_interaction.png)
    > El impacto del IMC en los costos depende crÃ­ticamente de si la persona fuma. Para los no fumadores, el costo apenas aumenta con el IMC. Para los fumadores, un IMC mÃ¡s alto se correlaciona con un aumento exponencial en los costos, demostrando una fuerte interacciÃ³n entre ambos factores.
*   **Matriz de CorrelaciÃ³n de Variables NumÃ©ricas**: Confirma las correlaciones entre `age`, `bmi` y `charges`.
    ![Matriz de CorrelaciÃ³n de Variables NumÃ©ricas](data/08_reporting/correlation_heatmap.png)
    > La correlaciÃ³n mÃ¡s fuerte con los costos (`charges`) es la edad (`age`), aunque sigue siendo moderada (0.30). El IMC (`bmi`) tiene una correlaciÃ³n mÃ¡s dÃ©bil (0.20). Esto refuerza que los modelos lineales simples con estas variables no serÃ¡n suficientes.

**GrÃ¡ficos de ClasificaciÃ³n y Ajuste de HiperparÃ¡metros:**
*   **Importancia de las CaracterÃ­sticas en el Modelo de RegresiÃ³n LogÃ­stica**: Muestra el impacto de cada variable en la clasificaciÃ³n.
    ![Importancia de las CaracterÃ­sticas en el Modelo de RegresiÃ³n LogÃ­stica](data/08_reporting/log_reg_feature_importance.png)
    > Ser fumador (`smoker_yes`) es, con diferencia, el factor que mÃ¡s aumenta la probabilidad de pertenecer a la categorÃ­a de "Alto" costo. La edad y el IMC tambiÃ©n contribuyen positivamente, mientras que ser hombre o pertenecer a ciertas regiones tiene un impacto negativo o menor.
*   **Heatmap de Resultados de GridSearchCV para Random Forest**: Visualiza el impacto de los hiperparÃ¡metros en la precisiÃ³n del modelo Random Forest.
    ![Heatmap de Resultados de GridSearchCV para Random Forest (Accuracy Promedio)](data/08_reporting/rf_grid_search_heatmap.png)
    > Este grÃ¡fico muestra cÃ³mo la combinaciÃ³n de hiperparÃ¡metros afecta la precisiÃ³n del modelo. Permite identificar visualmente la configuraciÃ³n Ã³ptima (en este caso, la zona mÃ¡s clara) que maximiza el rendimiento, justificando la selecciÃ³n del mejor modelo.
*   **Heatmap de Resultados de GridSearchCV para XGBoost**: Visualiza el impacto de los hiperparÃ¡metros en la precisiÃ³n del modelo XGBoost.
    ![Heatmap de Resultados de GridSearchCV para XGBoost (Accuracy Promedio)](data/08_reporting/xgb_grid_search_heatmap.png)
    > Al igual que con Random Forest, este mapa de calor guÃ­a la optimizaciÃ³n de XGBoost. Se puede observar cÃ³mo varÃ­an las precisiones al ajustar la tasa de aprendizaje y el nÃºmero de estimadores, asegurando que se elija la combinaciÃ³n mÃ¡s potente.
*   **Heatmap de Resultados de GridSearchCV para SVC**: Visualiza el impacto de los hiperparÃ¡metros en la precisiÃ³n del modelo SVC.
    ![Heatmap de Resultados de GridSearchCV para SVC (Accuracy Promedio)](data/08_reporting/svc_grid_search_heatmap.png)
    > El rendimiento del modelo SVC es muy sensible a los parÃ¡metros `C` (regularizaciÃ³n) y `gamma`. El mapa de calor revela quÃ© combinaciones evitan el sobreajuste o el subajuste, llevando a la mejor precisiÃ³n posible para este clasificador.

---

**En resumen:** El **Random Forest** es el modelo recomendado para la clasificaciÃ³n de costos mÃ©dicos en este proyecto, debido a su consistente y superior rendimiento en tÃ©rminos de precisiÃ³n despuÃ©s de un riguroso ajuste de hiperparÃ¡metros. El anÃ¡lisis de regresiÃ³n tambiÃ©n confirmÃ³ la importancia crÃ­tica de factores como el hÃ¡bito de fumar, la edad y el IMC en la determinaciÃ³n de los costos.

---

## ğŸ”‘ ConfiguraciÃ³n de Kaggle

Para poder ejecutar este pipeline, es necesario configurar las credenciales de la API de Kaggle.

1.  **Crea un token de API en Kaggle:**
    *   Ve a tu perfil de Kaggle y entra en la secciÃ³n "Settings": [https://www.kaggle.com/settings](https://www.kaggle.com/settings)
    *   En la secciÃ³n "API", haz clic en **"Create New Token"**. Se descargarÃ¡ un archivo llamado `kaggle.json`.

2.  **Coloca el archivo de credenciales:**
    *   Mueve el archivo `kaggle.json` a la carpeta `.kaggle` dentro de tu directorio de usuario.
        *   En Windows: `C:\Users\<Tu-Usuario>\.kaggle\kaggle.json`
        *   En Linux/macOS: `~/.kaggle/kaggle.json`

Una vez completados estos pasos, el pipeline podrÃ¡ autenticarse con Kaggle para descargar los datos necesarios.

---

## ğŸš€ InstalaciÃ³n y EjecuciÃ³n

Sigue estos pasos para configurar y ejecutar el proyecto en tu mÃ¡quina local. Se requiere Python 3.11.9.

### 1. Clonar el Repositorio

Primero, clona este repositorio.

```bash
git clone https://github.com/J-Lopez-IICG/MedicalCostKedro.git
cd MedicalCostKedro-WorkInProgress
```

### 2. Crear y Activar un Entorno Virtual

Es una prÃ¡ctica recomendada utilizar un entorno virtual para aislar las dependencias del proyecto.

```bash
# Crear el entorno virtual
python -m venv venv

# Activar en Windows (PowerShell)
.\venv\Scripts\Activate.ps1

# Activar en macOS/Linux
# source venv/bin/activate
```

### 3. Instalar Dependencias

Una vez que el entorno virtual estÃ© activado, instala todas las librerÃ­as necesarias.

```bash
pip install -r requirements.txt
```

### 4. Ejecutar el Pipeline

Con las dependencias instaladas, puedes ejecutar el pipeline completo con un solo comando.

```sh
kedro run
```

Esto ejecutarÃ¡ todos los nodos en secuencia, generando los datos limpios, los modelos entrenados y las grÃ¡ficas de resultados en la carpeta `data/`.

---

## ğŸ““ Desarrollo con Notebooks

La carpeta `notebooks` contiene los Jupyter Notebooks utilizados durante la fase de exploraciÃ³n y desarrollo.

Para trabajar con ellos de forma interactiva dentro del contexto de Kedro, ejecuta:

```bash
kedro jupyter lab
# o tambiÃ©n
kedro jupyter notebook
```

> **Nota**: Al usar estos comandos, Kedro inicia el notebook con las variables `context`, `session`, `catalog` y `pipelines` ya cargadas, facilitando la interacciÃ³n con los datos y funciones del proyecto.
